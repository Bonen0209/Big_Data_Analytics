{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.2.0.cloudera2\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.5.2 (default, Nov 23 2017 16:37:01)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "#Initial the spark\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#this part is used for pyspark submit\n",
    "os.environ['PYSPARK_SUBMIT_ARGS']='\\\n",
    "--verbose \\\n",
    "--master=yarn \\\n",
    "--deploy-mode=client \\\n",
    "pyspark-shell'\n",
    "\n",
    "os.environ['JAVA_HOME']='/usr/lib/jvm/java-8-openjdk-amd64/'\n",
    "os.environ['YARN_CONF_DIR']='/etc/alternatives/hadoop-conf/'\n",
    "\n",
    "#this line is used for spark2.2\n",
    "os.environ['SPARK_HOME']='/opt/cloudera/parcels/SPARK2-2.2.0.cloudera2-1.cdh5.12.0.p0.232957/lib/spark2'\n",
    "\n",
    "#this line is used for python3.5\n",
    "os.environ['PYSPARK_PYTHON']='/usr/bin/python3'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.4-src.zip'))  \n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import to change the types\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "#Read the file\n",
    "spWaferlog = spark.read \\\n",
    "             .format('csv') \\\n",
    "             .option('header', 'true') \\\n",
    "             .load('/user/homework_2/WaferLog.csv')\n",
    "\n",
    "spYield = spark.read \\\n",
    "          .format('csv') \\\n",
    "          .option('header', 'true') \\\n",
    "          .load('/user/homework_1/Yield.csv')\n",
    "\n",
    "#Rename the title\n",
    "spYield = spYield.withColumnRenamed('_c0', 'Wafer_ID')\n",
    "\n",
    "oldColumns = ['_c0', 'Lot.ID', 'Wafer.ID', 'Process.stage', 'Tool.ID']\n",
    "newColumns = ['number', 'Lot_ID', 'Wafer_ID', 'Process_stage', 'Tool_ID']\n",
    "\n",
    "for i in range(len(oldColumns)):\n",
    "    spWaferlog = spWaferlog.withColumnRenamed(oldColumns[i], newColumns[i])\n",
    "            \n",
    "#Change the schema\n",
    "spYield = spYield.withColumn('yield', spYield['yield'].cast(DoubleType()))\n",
    "spWaferlog = spWaferlog.withColumn('Process_stage', spWaferlog['Process_stage'].cast(IntegerType()))\n",
    "\n",
    "#Join the data\n",
    "spData = spYield.join(spWaferlog, 'Wafer_ID')\n",
    "\n",
    "#Pick the useful information\n",
    "spData = spData.select('Wafer_ID', 'yield', 'Process_stage', 'Time', 'Action') \\\n",
    "               .orderBy('Wafer_ID', 'Process_stage', 'Action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate the LOGIN and LOGOUT time\n",
    "spIn = spData.where(\"Action == 'LOGIN_TOOL'\")\n",
    "spOut = spData.where(\"Action == 'LOGOUT_TOOL'\")\n",
    "\n",
    "#Rename the title\n",
    "spIn = spIn.withColumnRenamed('Time', 'Qtime_OUT')\n",
    "spOut = spOut.withColumnRenamed('Time', 'Qtime_IN')\n",
    "\n",
    "#Minus the Process_stage\n",
    "spIn = spIn.withColumn('Process_stage', spIn['Process_stage'] - 1) \\\n",
    "           .select('Wafer_ID', 'Process_stage', 'Qtime_OUT') \\\n",
    "           .where(\"Process_stage > 0\")\n",
    "\n",
    "#Join two tables\n",
    "joinTables = ['Wafer_ID', 'Process_stage']\n",
    "spTotal = spOut.join(spIn, joinTables).orderBy('Wafer_ID', 'Process_stage')\n",
    "\n",
    "#Drop the Action\n",
    "spTotal = spTotal.drop('Action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the differences between two times\n",
    "from pyspark.sql import functions as f\n",
    "Duration = (f.unix_timestamp('Qtime_OUT') - f.unix_timestamp('Qtime_IN'))\n",
    "spTotal = spTotal.withColumn('Duration', Duration).orderBy('Wafer_ID', 'Process_stage')\n",
    "\n",
    "#Pearson correlation coefficient\n",
    "spResult = spTotal.groupBy('Process_stage') \\\n",
    "                  .agg(f.abs(f.corr('yield', 'Duration')).alias('Pearson')) \\\n",
    "                  .orderBy('Pearson', ascending = False)\n",
    "\n",
    "#Collect the result from spResult\n",
    "Results = spResult.select('Process_stage').rdd.flatMap(lambda x: x).collect()\n",
    "Results = Results[:5]\n",
    "\n",
    "#Select the data into pandas\n",
    "dfResults = []\n",
    "\n",
    "for index in Results:\n",
    "    dfResults.append(spTotal.where(spTotal.Process_stage == index) \\\n",
    "                           .select('yield', 'Duration').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Print the chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(dfResults)):\n",
    "    plt.title('Process_stage : ' + str(Results[i]))\n",
    "    plt.xlabel('Qtime')\n",
    "    plt.ylabel('Yield')\n",
    "    plt.scatter(dfResults[i]['Duration'], dfResults[i]['yield'])\n",
    "    plt.savefig('HW3_%s' %Results[i])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
